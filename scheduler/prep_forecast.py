# Puts the forecasts in a format that can be (relatively) quickly loaded by schedulerimport pandas as pdimport numpy as npimport jsonimport timefrom scipy.interpolate import CubicSplineimport matplotlib.pyplot as plt# First convert the representative wind/solar profile to a scaled version by BA# Read in the selected topology configurationwith open("topology_conf.json", "r") as f:    topology = json.load(f)# Load BA nameswith open("ba_names.json", "r") as f:    ba_names = json.load(f)    ba_names = sorted(ba_names['ba'])# Load solar/wind scale factorsba_ws_scale = pd.read_excel('market_clearing/system_data/wecc_solar_wind.xlsx',skiprows=3)# Load representative profileprofile = pd.read_csv('market_clearing/system_data/AZ_profile.csv')solar = profile.iloc[:,1].to_numpy()wind = profile.iloc[:,2].to_numpy()solar.reshape((1, len(solar)))wind.reshape((1, len(wind)))all_solar = np.zeros((solar.size, len(ba_names)))all_wind = np.zeros(all_solar.shape)for i, ba in enumerate(ba_names):    try:        sf = ba_ws_scale.loc[0,ba]        wf = ba_ws_scale.loc[1,ba]        if np.isnan(sf):            sf = 0        if np.isnan(wf):            wf = 0    except KeyError:        sf, wf = 0, 0    all_solar[:,i] = solar*sf    all_wind[:,i] = wind*wf    # Average the five minute data to get hourly solarhour_solar = np.zeros((int(solar.size/12), len(ba_names)))hour_wind = np.zeros(hour_solar.shape)for row in range(all_solar.shape[0]):    if row%12 == 0:        ridx = int(np.floor(row/12))        for col in range(all_solar.shape[1]):            hour_solar[ridx,col] = np.mean(all_solar[row:row+12,col])            hour_wind[ridx,col] = np.mean(all_wind[row:row+12,col])            solar_df = pd.DataFrame(all_solar, columns=ba_names)wind_df = pd.DataFrame(all_wind, columns=ba_names)solar_df_hour = pd.DataFrame(hour_solar, columns=ba_names)wind_df_hour = pd.DataFrame(hour_wind, columns=ba_names)# Save to parquet and csv (checking times for now just to see the difference)t0 = time.time()solar_df.to_parquet('market_clearing/system_data/solar_5min.parquet')wind_df.to_parquet('market_clearing/system_data/wind_5min.parquet')solar_df_hour.to_parquet('market_clearing/system_data/solar_1hr.parquet')wind_df_hour.to_parquet('market_clearing/system_data/wind_1hr.parquet')# TODO: update once we have the true acutalssolar_df.to_parquet('market_clearing/system_data/solar_5min_actual.parquet')wind_df.to_parquet('market_clearing/system_data/wind_5min_actual.parquet')solar_df_hour.to_parquet('market_clearing/system_data/solar_1hr_actual.parquet')wind_df_hour.to_parquet('market_clearing/system_data/wind_1hr_actual.parquet')t1 = time.time()test_spqt = pd.read_parquet('market_clearing/system_data/solar_5min.parquet')test_wpqt = pd.read_parquet('market_clearing/system_data/wind_5min.parquet')t2 = time.time()solar_df.to_csv('market_clearing/system_data/solar_5min.csv')wind_df.to_csv('market_clearing/system_data/wind_5min.csv')solar_df_hour.to_csv('market_clearing/system_data/solar_1hr.csv')wind_df_hour.to_csv('market_clearing/system_data/wind_1hr.csv')t3 = time.time()test_scsv = pd.read_csv('market_clearing/system_data/solar_5min.csv')test_wcsv = pd.read_csv('market_clearing/system_data/wind_5min.csv')t4 = time.time()print("Write time parquet:", t1-t0)print("Read time parquet:", t2-t1)print("Write time csv:", t3-t2)print("Read time csv:", t4-t3)# Now read in demand and save to parquetdemand_5min = pd.read_csv('market_clearing/system_data/New_Load_5min.csv')demand_5min = demand_5min.drop("Index", axis=1)demand_1hr = pd.read_csv('market_clearing/system_data/New_Load_1hr.csv')demand_5min.to_parquet('market_clearing/system_data/demand_5min.parquet')demand_1hr.to_parquet('market_clearing/system_data/demand_1hr.parquet')# TODO: update once we have the true acutalsdemand_5min.to_parquet('market_clearing/system_data/demand_5min_actual.parquet')demand_1hr.to_parquet('market_clearing/system_data/demand_1hr_actual.parquet')demand_5min.to_csv('market_clearing/system_data/demand_5min_actual.csv')demand_1hr.to_csv('market_clearing/system_data/demand_1hr_actual.csv')# Now read in hydro, interpolate to 5 min, and save to parquethydro_1hr = pd.read_csv('market_clearing/system_data/Hydro_2030_8760.csv')all_hydro = np.zeros(all_solar.shape)# Interpolate with cubic splinesfor i, ba in enumerate(ba_names):    hydro_prof = hydro_1hr.loc[:,ba].to_numpy()    x = np.arange(len(hydro_prof))    spline = CubicSpline(x, hydro_prof)    xdense = np.arange(0,len(hydro_prof),1./12)    fit = spline(xdense)    # Trim extreme values    fit[fit<0] = 0    fit[fit>np.max(hydro_prof)] = np.max(hydro_prof)    all_hydro[:,i] = fithydro_5min = pd.DataFrame(all_hydro, columns=ba_names)hydro_5min.to_parquet('market_clearing/system_data/hydro_5min.parquet')hydro_1hr.to_parquet('market_clearing/system_data/hydro_1hr.parquet')